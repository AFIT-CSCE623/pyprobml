{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flax_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGcXVUoVtHARr2Me0Wkumz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/mlp/flax_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF208fIxvq8m"
      },
      "source": [
        "# Introduction to neural networks using Flax\n",
        "\n",
        "\n",
        "\n",
        "Flax / Linen is a neural net library, built on top of JAX, \"designed to offer an implicit variable management API to save the user from having to manually thread thousands of variables through a complex tree of functions.\" To handle both current and future JAX transforms (configured and composed in any way), Linen Modules are defined as explicit functions of the form\n",
        "$$\n",
        "f(v_{in}, x) \\rightarrow v_{out}, y\n",
        "$$\n",
        "Where $v_{in}$ is the collection of variables (eg. parameters) and PRNG state used by the model, $v_{out}$ the mutated output variable collections, $x$ the input data and $y$ the output data. We illustrate this below. Our tutorial is based on the official [flax intro](https://flax.readthedocs.io/en/latest/notebooks/flax_basics.html) and [linen colab](https://github.com/google/flax/blob/master/docs/notebooks/linen_intro.ipynb). Details are in the [flax source code](https://flax.readthedocs.io/en/latest/_modules/index.html). Note: please be sure to read our [JAX tutorial](https://github.com/probml/pyprobml/blob/master/book1/intro/jax_intro.ipynb) first.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRAzAXYXvztz"
      },
      "source": [
        "import numpy as np\n",
        "#np.set_printoptions(precision=3)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('precision', 2) # 2 decimal places\n",
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', 30)\n",
        "pd.set_option('display.width', 100) # wide windows"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ob8P9ALvkcM",
        "outputId": "573415d3-eba0-4d6a-e51a-674aea067217"
      },
      "source": [
        "# Install the latest JAXlib version.\n",
        "!pip install --upgrade -q pip jax jaxlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 34.0 MB 115 kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68kI74E1vvEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3f450c-747f-43d1-f656-027c0f20840e"
      },
      "source": [
        "import jax\n",
        "from jax import lax, random, numpy as jnp\n",
        "key = random.PRNGKey(0)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3dXu6XY6U0H"
      },
      "source": [
        "from typing import Any, Callable, Dict, Iterator, Mapping, Optional, Sequence, Tuple\n",
        "\n",
        "# Useful type aliases\n",
        "Array = jnp.ndarray\n",
        "PRNGKey = Array\n",
        "Batch = Mapping[str, np.ndarray]\n",
        "OptState = Any"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcNcE9_Qj_l",
        "outputId": "078ce93a-a379-48a7-e19c-71ea186ca55f"
      },
      "source": [
        "# Install Flax at head:\n",
        "!pip install --upgrade -q git+https://github.com/google/flax.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for flax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s80k9sonQfDi"
      },
      "source": [
        "import flax\n",
        "from flax.core import freeze, unfreeze\n",
        "from flax import linen as nn\n",
        "from flax import optim\n",
        "\n",
        "from jax.config import config\n",
        "config.enable_omnistaging() # Linen requires enabling omnistaging"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrUFJYxjyL7"
      },
      "source": [
        "# MLP in vanilla JAX\n",
        "\n",
        "We construct a simple MLP with L hidden layers (relu activation), and scalar output (linear activation).\n",
        "\n",
        "Note: JAX and Flax, like NumPy, are row-based systems, meaning that vectors are represented as row vectors and not column vectors. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQGVJMP0VMB"
      },
      "source": [
        "# We define the parameter initializers using a signature that is flax-compatible\n",
        "# https://flax.readthedocs.io/en/latest/_modules/jax/_src/nn/initializers.html\n",
        "\n",
        "def weights_init(key, shape, dtype=jnp.float32):\n",
        "  return random.normal(key, shape, dtype)\n",
        "  #return jnp.ones(shape, dtype)\n",
        "\n",
        "def bias_init(key, shape, dtype=jnp.float32):\n",
        "  return jnp.zeros(shape, dtype)\n",
        "\n",
        "def relu(a):\n",
        "  return jnp.maximum(a, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GepkhhTh-9b-"
      },
      "source": [
        "# A minimal MLP class\n",
        "\n",
        "class MLP0():\n",
        "  features: Sequence[int] # number of features in each layer\n",
        "\n",
        "  def __init__(self, features): # class constructor\n",
        "    self.features = features\n",
        "\n",
        "  def init(self, key, x): # initialize parameters\n",
        "    in_size = np.shape(x)[1]\n",
        "    sizes = np.concatenate( ([in_size], self.features) )\n",
        "    nlayers = len(sizes)\n",
        "    params = {}\n",
        "    for i in range(nlayers-1):\n",
        "      in_size = sizes[i]\n",
        "      out_size = sizes[i+1]\n",
        "      subkey1, subkey2, key = random.split(key, num=3)\n",
        "      W = weights_init(subkey1, (in_size, out_size) )\n",
        "      b = bias_init(subkey2, out_size)\n",
        "      params[f'W{i}'] = W\n",
        "      params[f'b{i}'] = b\n",
        "    return params\n",
        "\n",
        "  def apply(self, params, x): # forwards pass\n",
        "    activations = x\n",
        "    nhidden_layers = len(self.features)-1\n",
        "    for i in range(nhidden_layers):\n",
        "      W = params[f'W{i}']; b = params[f'b{i}'];\n",
        "      outputs = jnp.dot(activations, W) + b\n",
        "      activations = relu(outputs)\n",
        "    # for final layer, no activation function\n",
        "    i = nhidden_layers\n",
        "    outputs = jnp.dot(activations, params[f'W{i}']) + params[f'b{i}']\n",
        "    return outputs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jFS4SNO0V_I",
        "outputId": "c9ea7bcd-9f31-48f5-be7e-aec6d11a265f"
      },
      "source": [
        "key = random.PRNGKey(0)\n",
        "D = 3\n",
        "N = 2\n",
        "x = random.normal(key, (N,D,))\n",
        "layer_sizes = [3,1] # 1 hidden layer of size 3, 1 scalar output\n",
        "\n",
        "\n",
        "model0 = MLP0(layer_sizes)\n",
        "params0 = model0.init(key, x)\n",
        "\n",
        "print('params')\n",
        "for k,v in params0.items():\n",
        "  print(k, v.shape)\n",
        "  print(v)\n",
        "\n",
        "y0 = model0.apply(params0, x)\n",
        "print('\\noutput')\n",
        "print(y0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params\n",
            "W0 (3, 3)\n",
            "[[-1.83021 1.18417 0.06777]\n",
            " [0.34588 0.37858 -0.65318]\n",
            " [0.18976 0.45157 -0.33964]]\n",
            "b0 (3,)\n",
            "[0.00000 0.00000 0.00000]\n",
            "W1 (3, 1)\n",
            "[[-1.74905]\n",
            " [1.83313]\n",
            " [-0.23808]]\n",
            "b1 (1,)\n",
            "[0.00000]\n",
            "\n",
            "output\n",
            "[[-0.09538]\n",
            " [2.78382]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBtPT-drBkGA"
      },
      "source": [
        "# Our first flax model\n",
        "\n",
        "Here we recreate the vanilla model in flax. Since we don't specify how the parameters are initialized, the behavior will not be identical to the vanilla model --- we will fix this below, but for now, we focus on model construction.\n",
        "\n",
        "We see that the model is a subclass of `nn.Module`, which is a subclass of Python's dataclass. The child class (written by the user) must define a `model.call(inputs)` method, that applies the function to the input, and a `model.setup()` method, that creates the modules inside this model.\n",
        "\n",
        "The module (parent) class defines two main methods: `model.apply(variables, input`, that applies the function to the input (and variables) to generate an output; and `model.init(key, input)`, that initializes the variables and returns them as a \"frozen dictionary\". This dictionary can contain multiple *kinds* of variables. In the example below, the only kind are parameters, which are immutable variables (that will usually get updated in an external optimization loop, as we show later). The parameters are  automatically named after the corresponding module (here, dense0, dense1, etc).  In this example, both modules are dense layers, so their parameters are a weight matrix (called 'kernel') and a bias vector.\n",
        "\n",
        "The hyper-parameters (in this case, the size of each layer) are stored as attributes of the class, and are specified when the module is constructed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zueDo1r0Qav"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "  default_attr: int = 42\n",
        "\n",
        "  def setup(self):\n",
        "    print('setup')\n",
        "    self.layers = [nn.Dense(feat) for feat in self.features]\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    print('call')\n",
        "    x = inputs\n",
        "    for i, lyr in enumerate(self.layers):\n",
        "      x = lyr(x)\n",
        "      if i != len(self.layers) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoYDn8lX7_ZH",
        "outputId": "c3b9c07a-b5df-4788-af9a-6fb72b52a537"
      },
      "source": [
        "key = random.PRNGKey(0)\n",
        "D = 3\n",
        "N = 2\n",
        "x = random.normal(key, (N,D,))\n",
        "layer_sizes = [3,1] # 1 hidden layer of size 3, 1 scalar output\n",
        "\n",
        "print('calling constructor')\n",
        "model = MLP(layer_sizes) # just initialize attributes of the object\n",
        "print('OUTPUT')\n",
        "print(model)\n",
        "\n",
        "print('\\ncalling init')\n",
        "variables = model.init(key, x)  # calls setup then __call___\n",
        "print('OUTPUT')\n",
        "print(variables)\n",
        "\n",
        "print('\\nW0')\n",
        "W0 = variables['params']['layers_0']['kernel']\n",
        "print(W0)\n",
        "\n",
        "print('Calling apply')\n",
        "y = model.apply(variables, x) # calls setup then __call___\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calling constructor\n",
            "OUTPUT\n",
            "MLP(\n",
            "    # attributes\n",
            "    features = [3, 1]\n",
            "    default_attr = 42\n",
            ")\n",
            "\n",
            "calling init\n",
            "setup\n",
            "call\n",
            "OUTPUT\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        layers_0: {\n",
            "            kernel: DeviceArray([[0.57725, 0.43926, 0.69045],\n",
            "                         [0.02542, 0.50461, 0.56675],\n",
            "                         [0.07185, 0.17350, -0.04227]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "        layers_1: {\n",
            "            kernel: DeviceArray([[0.24313],\n",
            "                         [0.94535],\n",
            "                         [-0.12602]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "\n",
            "W0\n",
            "[[0.57725 0.43926 0.69045]\n",
            " [0.02542 0.50461 0.56675]\n",
            " [0.07185 0.17350 -0.04227]]\n",
            "Calling apply\n",
            "setup\n",
            "call\n",
            "[[0.02978]\n",
            " [0.66403]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lwM1j1WksDG"
      },
      "source": [
        "# Compact modules\n",
        "\n",
        "To reduce the amount of boiler plate code, flax makes it possible to define a module just by writing the `call` method, avoiding the need to write a `setup` function. The corresponding layers will be created when the `init` funciton is called, so the input shape can be inferred lazily (when passed an input). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akq_iXXdktwb",
        "outputId": "1e9e80e3-9bdf-4653-bd7d-7266bd1424b5"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, feat in enumerate(self.features):\n",
        "      x = nn.Dense(feat)(x)\n",
        "      if i != len(self.features) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = MLP(layer_sizes)\n",
        "print(model)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "    # attributes\n",
            "    features = [3, 1]\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        Dense_0: {\n",
            "            kernel: DeviceArray([[0.28216, 1.03322, 0.07901],\n",
            "                         [0.15159, -0.50100, -0.22373],\n",
            "                         [-0.40327, -0.39875, -0.09402]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "        Dense_1: {\n",
            "            kernel: DeviceArray([[0.25432],\n",
            "                         [0.76792],\n",
            "                         [0.48329]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[[0.56035]\n",
            " [1.07065]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNiuZ54yB7Gj"
      },
      "source": [
        "# Explicit parameter initialization\n",
        "\n",
        "We can control the initialization of the random parameters in each submodule by specifying an init function. Below we show how to initialize our MLP to match the vanilla JAX model. We then check both methods give the same outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W_lEFsU4t04",
        "outputId": "f44c742a-c919-4fd3-9fa9-b659c246f102"
      },
      "source": [
        "def make_const_init(x):\n",
        "  def init_params(key, shape, dtype=jnp.float32):\n",
        "    return x\n",
        "  return init_params\n",
        "\n",
        "class MLP_init(nn.Module):\n",
        "  features: Sequence[int]\n",
        "  params_init: Dict\n",
        "\n",
        "  def setup(self):\n",
        "    nlayers = len(self.features)\n",
        "    layers = []\n",
        "    for i in range(nlayers):\n",
        "      W = self.params_init[f'W{i}'];\n",
        "      b = self.params_init[f'b{i}']; \n",
        "      weights_init = make_const_init(W)\n",
        "      bias_init = make_const_init(b)\n",
        "      layer = nn.Dense(self.features[i], kernel_init=weights_init, bias_init=bias_init)\n",
        "      layers.append(layer)\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, lyr in enumerate(self.layers):\n",
        "      x = lyr(x)\n",
        "      if i != len(self.layers) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n",
        "params_init = params0\n",
        "model = MLP_init(layer_sizes, params_init)\n",
        "print(model)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)\n",
        "\n",
        "assert np.allclose(y, y0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP_init(\n",
            "    # attributes\n",
            "    features = [3, 1]\n",
            "    params_init = {'W0': DeviceArray([[-1.83021, 1.18417, 0.06777],\n",
            "                 [0.34588, 0.37858, -0.65318],\n",
            "                 [0.18976, 0.45157, -0.33964]], dtype=float32), 'b0': DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32), 'W1': DeviceArray([[-1.74905],\n",
            "                 [1.83313],\n",
            "                 [-0.23808]], dtype=float32), 'b1': DeviceArray([0.00000], dtype=float32)}\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        layers_0: {\n",
            "            kernel: DeviceArray([[-1.83021, 1.18417, 0.06777],\n",
            "                         [0.34588, 0.37858, -0.65318],\n",
            "                         [0.18976, 0.45157, -0.33964]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "        layers_1: {\n",
            "            kernel: DeviceArray([[-1.74905],\n",
            "                         [1.83313],\n",
            "                         [-0.23808]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[[-0.09538]\n",
            " [2.78382]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63YD32Ty-iiD"
      },
      "source": [
        "# Nested modules\n",
        "\n",
        "We can embed an MLP inside an MLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwjaFly4-qeZ",
        "outputId": "597cf45a-e98b-4e7b-f08c-7946db5e2dfe"
      },
      "source": [
        "class MLP_nested(nn.Module):\n",
        "    features_nested: Sequence[int]\n",
        "    features_output: int\n",
        "\n",
        "    def setup(self):\n",
        "      self.mlp = MLP(self.features_nested)\n",
        "      self.output_layer = nn.Dense(self.features_output)\n",
        "\n",
        "    def __call__(self, x):\n",
        "      return self.output_layer(nn.relu(self.mlp(x)))\n",
        "\n",
        "\n",
        "model = MLP_nested([3,4], 1)\n",
        "print(model)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP_nested(\n",
            "    # attributes\n",
            "    features_nested = [3, 4]\n",
            "    features_output = 1\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        mlp: {\n",
            "            Dense_0: {\n",
            "                kernel: DeviceArray([[-0.63572, 0.33321, 0.62651],\n",
            "                             [-0.17779, 0.22005, 0.74431],\n",
            "                             [-0.97726, -0.47203, 0.43659]], dtype=float32),\n",
            "                bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "            },\n",
            "            Dense_1: {\n",
            "                kernel: DeviceArray([[0.22112, 0.87654, 0.22310, -1.22264],\n",
            "                             [-0.32240, 0.94956, -0.04660, 0.39572],\n",
            "                             [-0.03547, -0.75176, 0.35311, 0.59318]], dtype=float32),\n",
            "                bias: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "            },\n",
            "        },\n",
            "        output_layer: {\n",
            "            kernel: DeviceArray([[0.08588],\n",
            "                         [0.64215],\n",
            "                         [-0.46796],\n",
            "                         [-0.10338]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[[0.00000]\n",
            " [-0.21694]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuL88xCopD3J"
      },
      "source": [
        "We can also use the compact notation. The resulting parameters have slightly different names, and random initial values. (They can be made the same, of course.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeY9Jx9NreXm",
        "outputId": "65559e99-0fce-4df6-9e07-be24302c8c6c"
      },
      "source": [
        "class MLP_nested(nn.Module):\n",
        "    features_nested: Sequence[int]\n",
        "    features_output: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "      mlp = MLP(self.features_nested, name=\"my_nested_MLP\")\n",
        "      dense = nn.Dense(self.features_output)\n",
        "      return dense(nn.relu(mlp(x)))\n",
        "\n",
        "model = MLP_nested([3,4], 1)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FrozenDict({\n",
            "    params: {\n",
            "        my_nested_MLP: {\n",
            "            Dense_0: {\n",
            "                kernel: DeviceArray([[-0.22084, -0.04334, -0.92993],\n",
            "                             [-0.42234, 0.45470, -0.09518],\n",
            "                             [0.86117, 0.10712, 0.50940]], dtype=float32),\n",
            "                bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "            },\n",
            "            Dense_1: {\n",
            "                kernel: DeviceArray([[-0.17214, -0.46445, 0.01060, -0.84916],\n",
            "                             [0.56824, 0.08029, 0.90197, -0.04891],\n",
            "                             [0.65304, 0.74382, 0.71842, 0.96025]], dtype=float32),\n",
            "                bias: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "            },\n",
            "        },\n",
            "        Dense_0: {\n",
            "            kernel: DeviceArray([[0.88803],\n",
            "                         [-0.85732],\n",
            "                         [0.13939],\n",
            "                         [0.10748]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[[0.02943]\n",
            " [0.02495]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf8avaA_nGJ1"
      },
      "source": [
        "# Creating modules with parameters\n",
        "\n",
        "Now we illustrate how to create a module with its own parameters, instead of relying on composing built-in primitives. As an example, we write our own dense layer class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUJ98XpSnS8F",
        "outputId": "0238844e-3954-4591-943c-8072597f61d1"
      },
      "source": [
        "class SimpleDense(nn.Module):\n",
        "  features: int # num output features for this layer\n",
        "  kernel_init: Callable = nn.initializers.lecun_normal()\n",
        "  bias_init: Callable = nn.initializers.zeros\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    features_in = inputs.shape[-1] # infer shape from input\n",
        "    features_out = self.features\n",
        "    kernel = self.param('kernel', self.kernel_init, (features_in, features_out))\n",
        "    bias = self.param('bias', self.bias_init, (features_out,))\n",
        "    outputs = jnp.dot(inputs, kernel) + bias\n",
        "    return outputs\n",
        "\n",
        "\n",
        "model = SimpleDense(features=3)\n",
        "print(model)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleDense(\n",
            "    # attributes\n",
            "    features = 3\n",
            "    kernel_init = init\n",
            "    bias_init = zeros\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        kernel: DeviceArray([[0.32718, 0.05599, 0.17998],\n",
            "                     [-0.12295, 0.70712, 0.28972],\n",
            "                     [0.13731, -0.02853, -0.62830]], dtype=float32),\n",
            "        bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "[[0.30842 -0.91549 -0.74603]\n",
            " [0.36248 0.24616 0.36943]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJpBh933-GTW"
      },
      "source": [
        "# Stochastic layers\n",
        "\n",
        "Some layers may need a source of randomness. If so, we must pass them a PRNG in the `init` and `apply` functions, in addition to the PRNG used for parameter initialization. We illustrate this below using dropout. We construct two versions, one which is stochastic (for training), and one which is deterministic (for evaluation). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMSpLucO-Yfj",
        "outputId": "9726f1f3-ca25-4946-f9da-29692b1b034c"
      },
      "source": [
        "class Block(nn.Module):\n",
        "  features: int\n",
        "  training: bool\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    x = nn.Dense(self.features)(inputs)\n",
        "    x = nn.Dropout(rate=0.5)(x, deterministic=not self.training)\n",
        "    return x\n",
        "\n",
        "N = 1; D = 2;\n",
        "x = random.uniform(key, (N,D))\n",
        "\n",
        "model = Block(features=3, training=True)\n",
        "key = random.PRNGKey(0)\n",
        "variables = model.init({'params': key, 'dropout': key}, x)\n",
        "#variables = model.init(key, x) # cannot share the rng\n",
        "print('variables', variables)\n",
        "\n",
        "# Apply stochastic model\n",
        "for i in range(2):\n",
        "  key, subkey = random.split(key)\n",
        "  y = model.apply(variables, x, rngs={'dropout': subkey})\n",
        "  print(f'train output {i}, ', y)\n",
        "\n",
        "# Now make a deterministic version\n",
        "eval_model = Block(features=3, training=False)\n",
        "key = random.PRNGKey(0)\n",
        "#variables = eval_model.init({'params': key, 'dropout': key}, x)\n",
        "for i in range(2):\n",
        "  key, subkey = random.split(key)\n",
        "  y = eval_model.apply(variables, x, rngs={'dropout': subkey})\n",
        "  print(f'eval output {i}, ', y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "variables FrozenDict({\n",
            "    params: {\n",
            "        Dense_0: {\n",
            "            kernel: DeviceArray([[0.99988, -0.14086, -0.99796],\n",
            "                         [1.46673, 0.59637, 0.38263]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "train output 0,  [[0.00000 1.05814 0.00000]]\n",
            "train output 1,  [[3.12202 1.05814 0.32862]]\n",
            "eval output 0,  [[1.56101 0.52907 0.16431]]\n",
            "eval output 1,  [[1.56101 0.52907 0.16431]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHieB2aAumdg"
      },
      "source": [
        "# Mutable variables\n",
        "\n",
        "In addition to parameters, linen modules can contain other kinds of variables, which may be mutable as we illustrate below.\n",
        "Indeed, parameters are just a special case of variable.\n",
        "In particular, this line\n",
        "```\n",
        "p = self.param('param_name', init_fn, shape, dtype)\n",
        "```\n",
        "is a convenient shorthand for this:\n",
        "```\n",
        "p = self.variable('params', 'param_name', lambda s, d: init_fn(self.make_rng('params'), s, d), shape, dtype).value\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAQxx2Tu8xln"
      },
      "source": [
        "## Example: counter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeGNa8zaut41",
        "outputId": "eb8923e0-ed62-46f9-f11b-80dec053e31a"
      },
      "source": [
        "class Counter(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self):\n",
        "    # variable(collection, name, init_fn, *init_args)\n",
        "    counter1 = self.variable('counter', 'count1', lambda: jnp.zeros((), jnp.int32))\n",
        "    counter2 = self.variable('counter', 'count2', lambda: jnp.zeros((), jnp.int32))\n",
        "    is_initialized = self.has_variable('counter', 'count1')\n",
        "    if is_initialized:\n",
        "      counter1.value += 1\n",
        "      counter2.value += 2\n",
        "    return counter1.value, counter2.value\n",
        "\n",
        "\n",
        "model = Counter()\n",
        "print(model)\n",
        "\n",
        "init_variables = model.init(key) # calls the `call` method\n",
        "print('initialized variables:\\n', init_variables)\n",
        "counter = init_variables['counter']['count1']\n",
        "print('counter 1 value', counter)\n",
        "\n",
        "y, mutated_variables = model.apply(init_variables, mutable=['counter'])\n",
        "print('mutated variables:\\n', mutated_variables)\n",
        "print('output:\\n', y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter()\n",
            "initialized variables:\n",
            " FrozenDict({\n",
            "    counter: {\n",
            "        count1: DeviceArray(1, dtype=int32),\n",
            "        count2: DeviceArray(2, dtype=int32),\n",
            "    },\n",
            "})\n",
            "counter 1 value 1\n",
            "mutated variables:\n",
            " FrozenDict({\n",
            "    counter: {\n",
            "        count1: DeviceArray(2, dtype=int32),\n",
            "        count2: DeviceArray(4, dtype=int32),\n",
            "    },\n",
            "})\n",
            "output:\n",
            " (DeviceArray(2, dtype=int32), DeviceArray(4, dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IaC2RT1v65t"
      },
      "source": [
        "## Combining mutable variables and immutable parameters\n",
        "\n",
        "We can combine mutable variables with immutable parameters.\n",
        "As an example, consider a simplified version of batch normalization, which \n",
        " computes the running mean of its inputs, and adds an optimzable offset (bias) term. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXP19telv_Y_"
      },
      "source": [
        "class BiasAdderWithRunningMean(nn.Module):\n",
        "  decay: float = 0.99\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    is_initialized = self.has_variable('params', 'bias')\n",
        "\n",
        "    # variable(collection, name, init_fn, *init_args)\n",
        "    ra_mean = self.variable('batch_stats', 'mean', lambda s: jnp.zeros(s), x.shape[1:])\n",
        "\n",
        "    dummy_mutable = self.variable('mutables', 'dummy', lambda s: 42, 0)\n",
        "\n",
        "    # param(name, init_fn, *init_args)\n",
        "    bias = self.param('bias', lambda rng, shape: jnp.ones(shape), x.shape[1:]) \n",
        "\n",
        "    if is_initialized:\n",
        "      ra_mean.value = self.decay * ra_mean.value + (1.0 - self.decay) * jnp.mean(x, axis=0, keepdims=True)\n",
        "\n",
        "    return x - ra_mean.value + bias\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_WsMGY8xA_x"
      },
      "source": [
        "\n",
        "The intial variables are:\n",
        "params = (bias=1), batch_stats=(mean=0)\n",
        "\n",
        "If we pass in x=ones(N,D), the  running average becomes\n",
        "$$\n",
        "0.99*0 + (1-0.99)*1 = 0.01\n",
        "$$\n",
        "and the output becomes\n",
        "$$\n",
        "1 - 0.01 + 1 = 1.99\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvXKCE8yxiTu",
        "outputId": "4ddb1117-32a0-481d-d8bb-876010d0e821"
      },
      "source": [
        "key = random.PRNGKey(0)\n",
        "N = 2\n",
        "D = 5\n",
        "x = jnp.ones((N,D))\n",
        "model = BiasAdderWithRunningMean()\n",
        "\n",
        "variables = model.init(key, x)\n",
        "print('initial variables:\\n', variables)\n",
        "nonstats, stats = variables.pop('batch_stats')\n",
        "print('nonstats', nonstats)\n",
        "print('stats', stats)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial variables:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "    },\n",
            "    mutables: {\n",
            "        dummy: 42,\n",
            "    },\n",
            "    params: {\n",
            "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "nonstats FrozenDict({\n",
            "    mutables: {\n",
            "        dummy: 42,\n",
            "    },\n",
            "    params: {\n",
            "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "stats FrozenDict({\n",
            "    mean: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytr2_w9U12PT",
        "outputId": "30555a51-9b09-4ef2-8222-98c9b52e4a47"
      },
      "source": [
        "y, mutables = model.apply(variables, x, mutable=['batch_stats'])\n",
        "print('output', y)\n",
        "print('mutables', mutables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output [[1.99000 1.99000 1.99000 1.99000 1.99000]\n",
            " [1.99000 1.99000 1.99000 1.99000 1.99000]]\n",
            "mutables FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([[0.01000, 0.01000, 0.01000, 0.01000, 0.01000]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1g2GW3f3B-Z"
      },
      "source": [
        "To call the function with the updated batch stats, we have to stitch together the new mutated state with the old state, as shown below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpBb21A72Bdj",
        "outputId": "d5ce7521-90c4-48a0-a180-4f02be5fe5f8"
      },
      "source": [
        "\n",
        "variables = unfreeze(nonstats)\n",
        "print(variables)\n",
        "variables['batch_stats'] = mutables['batch_stats']\n",
        "variables = freeze(variables)\n",
        "print(variables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'mutables': {'dummy': 42}, 'params': {'bias': DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32)}}\n",
            "FrozenDict({\n",
            "    mutables: {\n",
            "        dummy: 42,\n",
            "    },\n",
            "    params: {\n",
            "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
            "    },\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([[0.01000, 0.01000, 0.01000, 0.01000, 0.01000]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa7nH74Y5-Lg"
      },
      "source": [
        "If we pass in x=2*ones(N,D), the running average gets updated to\n",
        "$$\n",
        "0.99 * 0.01 + (1-0.99) * 2.0 = 0.0299\n",
        "$$\n",
        "and the output becomes\n",
        "$$\n",
        "2- 0.0299 + 1 = 2.9701\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2dF2si51QN5",
        "outputId": "6177ee1c-41b7-40e6-d954-d0c1c85b0180"
      },
      "source": [
        "\n",
        "x = 2*jnp.ones((N,D))\n",
        "y, mutables = model.apply(variables, x, mutable=['batch_stats'])\n",
        "print('output', y)\n",
        "print('batch_stats', mutables)\n",
        "\n",
        "assert np.allclose(y, 2.9701)\n",
        "assert np.allclose(mutables['batch_stats']['mean'], 0.0299)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output [[2.97010 2.97010 2.97010 2.97010 2.97010]\n",
            " [2.97010 2.97010 2.97010 2.97010 2.97010]]\n",
            "batch_stats FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([[0.02990, 0.02990, 0.02990, 0.02990, 0.02990]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnBmgGxOoPKU"
      },
      "source": [
        "# Optimization\n",
        "\n",
        "Flax has several built-in (first-order) optimizers, as we illustrate below on a random linear function. (Note that we can also fit a model defined in flax using some other kind of optimizer, such as that provided by the [optax library](https://github.com/deepmind/optax).)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTHgj_pMra3H",
        "outputId": "d142c2bb-c725-47e6-8cba-5b55f9f16b48"
      },
      "source": [
        "D = 5\n",
        "key = jax.random.PRNGKey(0)\n",
        "params = {'w': jax.random.normal(key, (D,))}\n",
        "print(params)\n",
        "\n",
        "x = jax.random.normal(key, (D,))\n",
        "\n",
        "def loss(params):\n",
        "  w = params['w']\n",
        "  return jnp.dot(x, w)\n",
        "\n",
        "loss_grad_fn = jax.value_and_grad(loss)\n",
        "v, g = loss_grad_fn(params)\n",
        "print(v)\n",
        "print(g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)}\n",
            "3.375659\n",
            "{'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KdmBHa8oWFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3695c5f5-339c-4e27-d80e-30d100ddae66"
      },
      "source": [
        "from flax import optim\n",
        "optimizer_def = optim.Momentum(learning_rate=0.1, beta=0.9)\n",
        "print(optimizer_def)\n",
        "\n",
        "optimizer = optimizer_def.create(params) \n",
        "print(optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<flax.optim.momentum.Momentum object at 0x7fbd09abceb8>\n",
            "Optimizer(optimizer_def=<flax.optim.momentum.Momentum object at 0x7fbd09abceb8>, state=OptimizerState(step=DeviceArray(0, dtype=int32), param_states={'w': _MomentumParamState(momentum=DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32))}), target={'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JpgauX_ox_w",
        "outputId": "c649c61c-93ba-41a0-a834-2c254a53a243"
      },
      "source": [
        "for i in range(10):\n",
        "  params = optimizer.target\n",
        "  loss_val, grad = loss_grad_fn(params)\n",
        "  optimizer = optimizer.apply_gradient(grad)\n",
        "  params = optimizer.target\n",
        "  print('step {}, loss {:0.3f}, params {}'.format(i, loss_val, params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, loss -10.593, params {'w': DeviceArray([-0.71837, 4.90788, 1.03673, -4.77677, -0.93493], dtype=float32)}\n",
            "step 1, loss -12.910, params {'w': DeviceArray([-0.85316, 5.82877, 1.23126, -5.67306, -1.11035], dtype=float32)}\n",
            "step 2, loss -15.332, params {'w': DeviceArray([-0.99326, 6.78590, 1.43345, -6.60462, -1.29268], dtype=float32)}\n",
            "step 3, loss -17.849, params {'w': DeviceArray([-1.13813, 7.77566, 1.64252, -7.56794, -1.48122], dtype=float32)}\n",
            "step 4, loss -20.453, params {'w': DeviceArray([-1.28730, 8.79477, 1.85780, -8.55983, -1.67536], dtype=float32)}\n",
            "step 5, loss -23.133, params {'w': DeviceArray([-1.44033, 9.84031, 2.07866, -9.57743, -1.87453], dtype=float32)}\n",
            "step 6, loss -25.884, params {'w': DeviceArray([-1.59685, 10.90963, 2.30454, -10.61818, -2.07823], dtype=float32)}\n",
            "step 7, loss -28.696, params {'w': DeviceArray([-1.75650, 12.00035, 2.53494, -11.67977, -2.28600], dtype=float32)}\n",
            "step 8, loss -31.565, params {'w': DeviceArray([-1.91897, 13.11033, 2.76941, -12.76010, -2.49745], dtype=float32)}\n",
            "step 9, loss -34.485, params {'w': DeviceArray([-2.08397, 14.23764, 3.00754, -13.85730, -2.71220], dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ITTDWT2ECxC"
      },
      "source": [
        "# Worked example\n",
        "\n",
        "We demonstrate how to fit a shallow MLP to MNIST using Flax.\n",
        "We use this function:\n",
        "https://github.com/probml/pyprobml/blob/master/scripts/fit_flax.py\n",
        "To allow us to edit this file locally (in colab), and push commits back to github, we sync this colab with github.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vavamofruHS_"
      },
      "source": [
        "## Import code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OhoJQUnuE1Q",
        "outputId": "d10078e1-e388-464c-9559-4d3ce140c098"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive/ssh/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "id_rsa\tid_rsa.pub  known_hosts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppe45L9BuSFe"
      },
      "source": [
        "\n",
        "def git_colab(\n",
        "    git_command, email=\"murphyk@gmail.com\", username=\"probml\", verbose=False):\n",
        "  git_command=git_command.replace(r\"https://github.com/\",\"git@github.com:\")\n",
        "  print('executing command:', git_command)\n",
        "  # copy keys from drive to local .ssh folder\n",
        "  if verbose:\n",
        "    print('Copying keys from gdrive to local VM')\n",
        "  !rm -rf ~/.ssh/\n",
        "  !mkdir ~/.ssh/\n",
        "  !cp  -r /content/drive/MyDrive/ssh/* ~/.ssh/\n",
        "  if verbose:\n",
        "    !ls ~/.ssh/\n",
        "  # configure ssh and test it\n",
        "  if verbose:\n",
        "    print('Setup SSH')\n",
        "  !ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
        "  !ssh -T git@github.com\n",
        "  # git commands\n",
        "  if verbose:\n",
        "    print('Executing git commands')\n",
        "  !git config --global user.email $email\n",
        "  !git config --global user.name $username\n",
        "  !$git_command\n",
        "  # cleanup\n",
        "  if verbose:\n",
        "    print('Cleanup local VM')\n",
        "  !rm -r ~/.ssh/\n",
        "  !git config --global user.email \"\"\n",
        "  !git config --global user.name \"\"\n",
        "  # check that cleanup worked\n",
        "  #!ssh -T git@github.com # should say 'Host key verification failed'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUYY3-N4uWYh",
        "outputId": "8695bbe0-93a9-4580-c58e-779ccb6433c4"
      },
      "source": [
        "!rm -rf pyprobml\n",
        "git_colab(\"git clone https://github.com/probml/pyprobml.git\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "executing command: git clone git@github.com:probml/pyprobml.git\n",
            "# github.com:22 SSH-2.0-babeld-ccb88c3b\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.113.3' to the list of known hosts.\n",
            "Hi murphyk! You've successfully authenticated, but GitHub does not provide shell access.\n",
            "Cloning into 'pyprobml'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 5672 (delta 64), reused 59 (delta 24), pack-reused 5555\u001b[K\n",
            "Receiving objects: 100% (5672/5672), 198.35 MiB | 26.61 MiB/s, done.\n",
            "Resolving deltas: 100% (3206/3206), done.\n",
            "Checking out files: 100% (482/482), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjUVc9yKvFFP"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKnFd4MFu_jE",
        "outputId": "9a4ace28-760e-4c3c-9e4b-c975334f5a31"
      },
      "source": [
        "\n",
        "import pyprobml.scripts.fit_flax as ff\n",
        "ff.test()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing fit-flax\n",
            "train step: 0, loss: 1.5363, accuracy: 0.33\n",
            "train step: 1, loss: 1.3916, accuracy: 0.33\n",
            "test passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJXwfqz0-_XJ",
        "outputId": "9191777d-61c1-432a-c5f2-e4d18b109422"
      },
      "source": [
        "# If made any local changes to fit_flax.py, save them to github\n",
        "%cd /content/pyprobml\n",
        "git_colab(\"git add scripts; git commit -m 'push from colab'; git push\")\n",
        "%cd /content"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pyprobml\n",
            "executing command: git add scripts; git commit -m 'push from colab'; git push\n",
            "# github.com:22 SSH-2.0-babeld-ccb88c3b\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.114.3' to the list of known hosts.\n",
            "Hi murphyk! You've successfully authenticated, but GitHub does not provide shell access.\n",
            "[master 7002db7] push from colab\n",
            " 3 files changed, 42 insertions(+), 28 deletions(-)\n",
            " create mode 100644 scripts/__pycache__/__init__.cpython-36.pyc\n",
            " create mode 100644 scripts/__pycache__/fit_flax.cpython-36.pyc\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.113.4' to the list of known hosts.\n",
            "Counting objects: 7, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (7/7), 3.68 KiB | 3.68 MiB/s, done.\n",
            "Total 7 (delta 4), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To github.com:probml/pyprobml.git\n",
            "   18f72a1..7002db7  master -> master\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_xSZi3v03pC"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klFERmagmBlr",
        "outputId": "afd36883-6978-4290-a35e-ae1c390b74cb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def process_tf(batch):\n",
        "  image = batch['image']\n",
        "  X = tf.cast(image, tf.float32) / 255. # TF yuck\n",
        "  X = tf.reshape(X, [-1, 28*28*1]) # flatten # gives (bs,1,784) - why the 1?\n",
        "  d = {'X': X,\n",
        "        'y': batch['label']}\n",
        "  return d\n",
        "\n",
        "def load_dataset_mnist(split: tfds.Split, batch_size: int) -> Iterator[Batch]:\n",
        "  ds, ds_info = tfds.load(\"mnist\", split=split, with_info=True)\n",
        "  #ds = ds.map(process_tf)\n",
        "  # For true randomness, we set the shuffle buffer to the full dataset size.\n",
        "  ds = ds.shuffle(ds_info.splits[split].num_examples)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  ds = ds.repeat()\n",
        "  ds = tfds.as_numpy(ds)\n",
        "  return iter(ds)\n",
        "\n",
        "\n",
        "batch_size = 30\n",
        "train_ds = load_dataset_mnist(tfds.Split.TRAIN, batch_size)\n",
        "batch = next(train_ds)\n",
        "print(batch['image'].shape)\n",
        "print(batch['label'].shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 28, 28, 1)\n",
            "(30,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-DNEPsXtWVO",
        "outputId": "aa3dd293-4cc0-4d8c-aa1e-3c7f1982bb18"
      },
      "source": [
        "def preprocess_batch(batch, rng): #numpy version\n",
        "  X = batch['image']\n",
        "  y = batch['label']\n",
        "  X = np.reshape(X, (X.shape[0], -1))\n",
        "  X = X.astype(np.float32)/255\n",
        "  return {'X': X, 'y': y}\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "batch = next(train_ds)\n",
        "batch2 = preprocess_batch(batch, rng)\n",
        "print(batch2['X'].shape)\n",
        "print(batch2['y'].shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 784)\n",
            "(30,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLiWUSjR05BQ"
      },
      "source": [
        "## Model\n",
        "\n",
        "We fit a one layer MLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLwAwqd4Nzvy"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  nhidden: int\n",
        "  nclasses: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    if self.nhidden > 0:\n",
        "      x = nn.Dense(self.nhidden)(x)\n",
        "      x = nn.relu(x)\n",
        "    x = nn.Dense(self.nclasses)(x) # logits\n",
        "    x = nn.log_softmax(x) # log probabilities\n",
        "    return x\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JsVFGfU628j"
      },
      "source": [
        "## Training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gup-OrNpLXr"
      },
      "source": [
        "\n",
        "\n",
        "batch_size = 32 \n",
        "train_ds = load_dataset_mnist(tfds.Split.TRAIN, batch_size)\n",
        "test_ds = load_dataset_mnist(tfds.Split.TEST, batch_size)\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "KDAJthPTvxI7",
        "outputId": "2f4ec3f2-66d3-41f2-9949-9d83ae6fab7c"
      },
      "source": [
        "\n",
        "\n",
        "model = Model(nhidden = 128, nclasses=10) \n",
        "make_optimizer = optim.Momentum(learning_rate=0.1, beta=0.9)\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "num_steps = 200\n",
        "\n",
        "params, history =  ff.fit_model(model, train_ds, test_ds,  rng,\n",
        "        num_steps, make_optimizer,\n",
        "        ff.train_batch, ff.eval_batch, \n",
        "        preprocess_batch, preprocess_batch,\n",
        "        print_every=20, eval_every=10)\n",
        "  \n",
        "display(history)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train step: 0, loss: 2.2918, accuracy: 0.06\n",
            "train step: 20, loss: 0.6349, accuracy: 0.78\n",
            "train step: 40, loss: 0.6069, accuracy: 0.84\n",
            "train step: 60, loss: 0.4478, accuracy: 0.81\n",
            "train step: 80, loss: 0.4686, accuracy: 0.88\n",
            "train step: 100, loss: 0.3017, accuracy: 0.91\n",
            "train step: 120, loss: 0.1735, accuracy: 0.94\n",
            "train step: 140, loss: 0.3106, accuracy: 0.91\n",
            "train step: 160, loss: 0.6105, accuracy: 0.81\n",
            "train step: 180, loss: 0.3651, accuracy: 0.91\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>step</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.291816</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>2.1925316</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0505036</td>\n",
              "      <td>0.6875</td>\n",
              "      <td>0.6787044</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6348655</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>0.93267494</td>\n",
              "      <td>0.75</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.71225876</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.7959888</td>\n",
              "      <td>0.75</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6069384</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>1.0194508</td>\n",
              "      <td>0.6875</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0487291</td>\n",
              "      <td>0.46875</td>\n",
              "      <td>0.20958795</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.44783282</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.23956208</td>\n",
              "      <td>0.90625</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.5908326</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>0.26034525</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.46860686</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.50722677</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.60748434</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>0.38800564</td>\n",
              "      <td>0.90625</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.30171487</td>\n",
              "      <td>0.90625</td>\n",
              "      <td>0.33872464</td>\n",
              "      <td>0.90625</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.22036509</td>\n",
              "      <td>0.90625</td>\n",
              "      <td>0.53774285</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>110.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.17346942</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.5503266</td>\n",
              "      <td>0.875</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.74088174</td>\n",
              "      <td>0.71875</td>\n",
              "      <td>0.7956348</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.31062064</td>\n",
              "      <td>0.90625</td>\n",
              "      <td>0.32340738</td>\n",
              "      <td>0.875</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.43878475</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>0.16685899</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.61051655</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.49482712</td>\n",
              "      <td>0.875</td>\n",
              "      <td>160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.21360731</td>\n",
              "      <td>0.90625</td>\n",
              "      <td>0.2966485</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>170.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.3650651</td>\n",
              "      <td>0.90625</td>\n",
              "      <td>0.25540534</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.578213</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>0.576244</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>190.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    train_loss train_accuracy   test_loss test_accuracy   step\n",
              "0     2.291816         0.0625   2.1925316       0.28125    0.0\n",
              "1    1.0505036         0.6875   0.6787044       0.84375   10.0\n",
              "2    0.6348655        0.78125  0.93267494          0.75   20.0\n",
              "3   0.71225876           0.75   0.7959888          0.75   30.0\n",
              "4    0.6069384        0.84375   1.0194508        0.6875   40.0\n",
              "5    1.0487291        0.46875  0.20958795        0.9375   50.0\n",
              "6   0.44783282         0.8125  0.23956208       0.90625   60.0\n",
              "7    0.5908326        0.84375  0.26034525        0.9375   70.0\n",
              "8   0.46860686          0.875  0.50722677       0.78125   80.0\n",
              "9   0.60748434        0.84375  0.38800564       0.90625   90.0\n",
              "10  0.30171487        0.90625  0.33872464       0.90625  100.0\n",
              "11  0.22036509        0.90625  0.53774285       0.84375  110.0\n",
              "12  0.17346942         0.9375   0.5503266         0.875  120.0\n",
              "13  0.74088174        0.71875   0.7956348       0.78125  130.0\n",
              "14  0.31062064        0.90625  0.32340738         0.875  140.0\n",
              "15  0.43878475        0.84375  0.16685899        0.9375  150.0\n",
              "16  0.61051655         0.8125  0.49482712         0.875  160.0\n",
              "17  0.21360731        0.90625   0.2966485       0.84375  170.0\n",
              "18   0.3650651        0.90625  0.25540534        0.9375  180.0\n",
              "19    0.578213        0.84375    0.576244        0.8125  190.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "RWv2Sspl8EAN",
        "outputId": "cef14c5b-a3e6-4c51-e499-c93940aec10e"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(history['step'], history['test_accuracy'], 'o-', label='test accuracy')\n",
        "plt.xlabel('num. minibatches')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWe69Z51Q3Kz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}