{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flax_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNEOlFTdwCkuCRRZssvIdqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/mlp/flax_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF208fIxvq8m"
      },
      "source": [
        "# Introduction to neural networks using Flax\n",
        "\n",
        "\n",
        "\n",
        "Flax / Linen is a neural net library, built on top of JAX, \"designed to offer an implicit variable management API to save the user from having to manually thread thousands of variables through a complex tree of functions.\" To handle both current and future JAX transforms (configured and composed in any way), Linen Modules are defined as explicit functions of the form\n",
        "$$\n",
        "f(v_{in}, x) \\rightarrow v_{out}, y\n",
        "$$\n",
        "Where $v_{in}$ is the collection of variables (eg. parameters) and PRNG state used by the model, $v_{out}$ the mutated output variable collections, $x$ the input data and $y$ the output data. We illustrate this below. Our tutorial is based on the official [flax intro](https://flax.readthedocs.io/en/latest/notebooks/flax_basics.html) and [linen colab](https://github.com/google/flax/blob/master/docs/notebooks/linen_intro.ipynb). Details are in the [flax source code](https://flax.readthedocs.io/en/latest/_modules/index.html). Note: please be sure to read our [JAX tutorial](https://github.com/probml/pyprobml/blob/master/book1/intro/jax_intro.ipynb) first.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRAzAXYXvztz"
      },
      "source": [
        "import numpy as np\n",
        "#np.set_printoptions(precision=3)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('precision', 2) # 2 decimal places\n",
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', 30)\n",
        "pd.set_option('display.width', 100) # wide windows"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ob8P9ALvkcM",
        "outputId": "573415d3-eba0-4d6a-e51a-674aea067217"
      },
      "source": [
        "# Install the latest JAXlib version.\n",
        "!pip install --upgrade -q pip jax jaxlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 34.0 MB 115 kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68kI74E1vvEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5d7b52-dde1-4b7a-a063-28f56b49a7fb"
      },
      "source": [
        "import jax\n",
        "from jax import lax, random, numpy as jnp\n",
        "key = random.PRNGKey(0)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3dXu6XY6U0H"
      },
      "source": [
        "from typing import Any, Callable, Dict, Iterator, Mapping, Optional, Sequence, Tuple\n",
        "\n",
        "# Useful type aliases\n",
        "Array = jnp.ndarray\n",
        "PRNGKey = Array\n",
        "Batch = Mapping[str, np.ndarray]\n",
        "OptState = Any"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcNcE9_Qj_l",
        "outputId": "09b4fd90-a53a-4d00-d182-a9dc8b7fdd58"
      },
      "source": [
        "# Install Flax at head:\n",
        "!pip install --upgrade -q git+https://github.com/google/flax.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for flax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s80k9sonQfDi"
      },
      "source": [
        "import flax\n",
        "from flax.core import freeze, unfreeze\n",
        "from flax import linen as nn\n",
        "from flax import optim\n",
        "\n",
        "from jax.config import config\n",
        "config.enable_omnistaging() # Linen requires enabling omnistaging"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrUFJYxjyL7"
      },
      "source": [
        "# MLP in vanilla JAX\n",
        "\n",
        "We construct a simple MLP with L hidden layers (relu activation), and scalar output (linear activation).\n",
        "\n",
        "Note: JAX and Flax, like NumPy, are row-based systems, meaning that vectors are represented as row vectors and not column vectors. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQGVJMP0VMB"
      },
      "source": [
        "# We define the parameter initializers using a signature that is flax-compatible\n",
        "# https://flax.readthedocs.io/en/latest/_modules/jax/_src/nn/initializers.html\n",
        "\n",
        "def weights_init(key, shape, dtype=jnp.float32):\n",
        "  return random.normal(key, shape, dtype)\n",
        "  #return jnp.ones(shape, dtype)\n",
        "\n",
        "def bias_init(key, shape, dtype=jnp.float32):\n",
        "  return jnp.zeros(shape, dtype)\n",
        "\n",
        "def relu(a):\n",
        "  return jnp.maximum(a, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GepkhhTh-9b-"
      },
      "source": [
        "# A minimal MLP class\n",
        "\n",
        "class MLP0():\n",
        "  features: Sequence[int] # number of features in each layer\n",
        "\n",
        "  def __init__(self, features): # class constructor\n",
        "    self.features = features\n",
        "\n",
        "  def init(self, key, x): # initialize parameters\n",
        "    in_size = np.shape(x)[1]\n",
        "    sizes = np.concatenate( ([in_size], self.features) )\n",
        "    nlayers = len(sizes)\n",
        "    params = {}\n",
        "    for i in range(nlayers-1):\n",
        "      in_size = sizes[i]\n",
        "      out_size = sizes[i+1]\n",
        "      subkey1, subkey2, key = random.split(key, num=3)\n",
        "      W = weights_init(subkey1, (in_size, out_size) )\n",
        "      b = bias_init(subkey2, out_size)\n",
        "      params[f'W{i}'] = W\n",
        "      params[f'b{i}'] = b\n",
        "    return params\n",
        "\n",
        "  def apply(self, params, x): # forwards pass\n",
        "    activations = x\n",
        "    nhidden_layers = len(self.features)-1\n",
        "    for i in range(nhidden_layers):\n",
        "      W = params[f'W{i}']; b = params[f'b{i}'];\n",
        "      outputs = jnp.dot(activations, W) + b\n",
        "      activations = relu(outputs)\n",
        "    # for final layer, no activation function\n",
        "    i = nhidden_layers\n",
        "    outputs = jnp.dot(activations, params[f'W{i}']) + params[f'b{i}']\n",
        "    return outputs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jFS4SNO0V_I",
        "outputId": "c9ea7bcd-9f31-48f5-be7e-aec6d11a265f"
      },
      "source": [
        "key = random.PRNGKey(0)\n",
        "D = 3\n",
        "N = 2\n",
        "x = random.normal(key, (N,D,))\n",
        "layer_sizes = [3,1] # 1 hidden layer of size 3, 1 scalar output\n",
        "\n",
        "\n",
        "model0 = MLP0(layer_sizes)\n",
        "params0 = model0.init(key, x)\n",
        "\n",
        "print('params')\n",
        "for k,v in params0.items():\n",
        "  print(k, v.shape)\n",
        "  print(v)\n",
        "\n",
        "y0 = model0.apply(params0, x)\n",
        "print('\\noutput')\n",
        "print(y0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params\n",
            "W0 (3, 3)\n",
            "[[-1.83021 1.18417 0.06777]\n",
            " [0.34588 0.37858 -0.65318]\n",
            " [0.18976 0.45157 -0.33964]]\n",
            "b0 (3,)\n",
            "[0.00000 0.00000 0.00000]\n",
            "W1 (3, 1)\n",
            "[[-1.74905]\n",
            " [1.83313]\n",
            " [-0.23808]]\n",
            "b1 (1,)\n",
            "[0.00000]\n",
            "\n",
            "output\n",
            "[[-0.09538]\n",
            " [2.78382]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBtPT-drBkGA"
      },
      "source": [
        "# Our first flax model\n",
        "\n",
        "Here we recreate the vanilla model in flax. Since we don't specify how the parameters are initialized, the behavior will not be identical to the vanilla model --- we will fix this below, but for now, we focus on model construction.\n",
        "\n",
        "We see that the model is a subclass of `nn.Module`, which is a subclass of Python's dataclass. The child class (written by the user) must define a `model.call(inputs)` method, that applies the function to the input, and a `model.setup()` method, that creates the modules inside this model.\n",
        "\n",
        "The module (parent) class defines two main methods: `model.apply(variables, input`, that applies the function to the input (and variables) to generate an output; and `model.init(key, input)`, that initializes the variables and returns them as a \"frozen dictionary\". This dictionary can contain multiple *kinds* of variables. In the example below, the only kind are parameters, which are immutable variables (that will usually get updated in an external optimization loop, as we show later). The parameters are  automatically named after the corresponding module (here, dense0, dense1, etc).  In this example, both modules are dense layers, so their parameters are a weight matrix (called 'kernel') and a bias vector.\n",
        "\n",
        "The hyper-parameters (in this case, the size of each layer) are stored as attributes of the class, and are specified when the module is constructed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zueDo1r0Qav"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "  default_attr: int = 42\n",
        "\n",
        "  def setup(self):\n",
        "    print('setup')\n",
        "    self.layers = [nn.Dense(feat) for feat in self.features]\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    print('call')\n",
        "    x = inputs\n",
        "    for i, lyr in enumerate(self.layers):\n",
        "      x = lyr(x)\n",
        "      if i != len(self.layers) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoYDn8lX7_ZH",
        "outputId": "c3b9c07a-b5df-4788-af9a-6fb72b52a537"
      },
      "source": [
        "key = random.PRNGKey(0)\n",
        "D = 3\n",
        "N = 2\n",
        "x = random.normal(key, (N,D,))\n",
        "layer_sizes = [3,1] # 1 hidden layer of size 3, 1 scalar output\n",
        "\n",
        "print('calling constructor')\n",
        "model = MLP(layer_sizes) # just initialize attributes of the object\n",
        "print('OUTPUT')\n",
        "print(model)\n",
        "\n",
        "print('\\ncalling init')\n",
        "variables = model.init(key, x)  # calls setup then __call___\n",
        "print('OUTPUT')\n",
        "print(variables)\n",
        "\n",
        "print('\\nW0')\n",
        "W0 = variables['params']['layers_0']['kernel']\n",
        "print(W0)\n",
        "\n",
        "print('Calling apply')\n",
        "y = model.apply(variables, x) # calls setup then __call___\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calling constructor\n",
            "OUTPUT\n",
            "MLP(\n",
            "    # attributes\n",
            "    features = [3, 1]\n",
            "    default_attr = 42\n",
            ")\n",
            "\n",
            "calling init\n",
            "setup\n",
            "call\n",
            "OUTPUT\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        layers_0: {\n",
            "            kernel: DeviceArray([[0.57725, 0.43926, 0.69045],\n",
            "                         [0.02542, 0.50461, 0.56675],\n",
            "                         [0.07185, 0.17350, -0.04227]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "        layers_1: {\n",
            "            kernel: DeviceArray([[0.24313],\n",
            "                         [0.94535],\n",
            "                         [-0.12602]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "\n",
            "W0\n",
            "[[0.57725 0.43926 0.69045]\n",
            " [0.02542 0.50461 0.56675]\n",
            " [0.07185 0.17350 -0.04227]]\n",
            "Calling apply\n",
            "setup\n",
            "call\n",
            "[[0.02978]\n",
            " [0.66403]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lwM1j1WksDG"
      },
      "source": [
        "# Compact modules\n",
        "\n",
        "To reduce the amount of boiler plate code, flax makes it possible to define a module just by writing the `call` method, avoiding the need to write a `setup` function. The corresponding layers will be created when the `init` funciton is called, so the input shape can be inferred lazily (when passed an input). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akq_iXXdktwb",
        "outputId": "1e9e80e3-9bdf-4653-bd7d-7266bd1424b5"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, feat in enumerate(self.features):\n",
        "      x = nn.Dense(feat)(x)\n",
        "      if i != len(self.features) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = MLP(layer_sizes)\n",
        "print(model)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "    # attributes\n",
            "    features = [3, 1]\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        Dense_0: {\n",
            "            kernel: DeviceArray([[0.28216, 1.03322, 0.07901],\n",
            "                         [0.15159, -0.50100, -0.22373],\n",
            "                         [-0.40327, -0.39875, -0.09402]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "        Dense_1: {\n",
            "            kernel: DeviceArray([[0.25432],\n",
            "                         [0.76792],\n",
            "                         [0.48329]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[[0.56035]\n",
            " [1.07065]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNiuZ54yB7Gj"
      },
      "source": [
        "# Explicit parameter initialization\n",
        "\n",
        "We can control the initialization of the random parameters in each submodule by specifying an init function. Below we show how to initialize our MLP to match the vanilla JAX model. We then check both methods give the same outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W_lEFsU4t04",
        "outputId": "f44c742a-c919-4fd3-9fa9-b659c246f102"
      },
      "source": [
        "def make_const_init(x):\n",
        "  def init_params(key, shape, dtype=jnp.float32):\n",
        "    return x\n",
        "  return init_params\n",
        "\n",
        "class MLP_init(nn.Module):\n",
        "  features: Sequence[int]\n",
        "  params_init: Dict\n",
        "\n",
        "  def setup(self):\n",
        "    nlayers = len(self.features)\n",
        "    layers = []\n",
        "    for i in range(nlayers):\n",
        "      W = self.params_init[f'W{i}'];\n",
        "      b = self.params_init[f'b{i}']; \n",
        "      weights_init = make_const_init(W)\n",
        "      bias_init = make_const_init(b)\n",
        "      layer = nn.Dense(self.features[i], kernel_init=weights_init, bias_init=bias_init)\n",
        "      layers.append(layer)\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, lyr in enumerate(self.layers):\n",
        "      x = lyr(x)\n",
        "      if i != len(self.layers) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n",
        "params_init = params0\n",
        "model = MLP_init(layer_sizes, params_init)\n",
        "print(model)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)\n",
        "\n",
        "assert np.allclose(y, y0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP_init(\n",
            "    # attributes\n",
            "    features = [3, 1]\n",
            "    params_init = {'W0': DeviceArray([[-1.83021, 1.18417, 0.06777],\n",
            "                 [0.34588, 0.37858, -0.65318],\n",
            "                 [0.18976, 0.45157, -0.33964]], dtype=float32), 'b0': DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32), 'W1': DeviceArray([[-1.74905],\n",
            "                 [1.83313],\n",
            "                 [-0.23808]], dtype=float32), 'b1': DeviceArray([0.00000], dtype=float32)}\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        layers_0: {\n",
            "            kernel: DeviceArray([[-1.83021, 1.18417, 0.06777],\n",
            "                         [0.34588, 0.37858, -0.65318],\n",
            "                         [0.18976, 0.45157, -0.33964]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "        layers_1: {\n",
            "            kernel: DeviceArray([[-1.74905],\n",
            "                         [1.83313],\n",
            "                         [-0.23808]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[[-0.09538]\n",
            " [2.78382]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63YD32Ty-iiD"
      },
      "source": [
        "# Nested modules\n",
        "\n",
        "We can embed an MLP inside an MLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwjaFly4-qeZ",
        "outputId": "597cf45a-e98b-4e7b-f08c-7946db5e2dfe"
      },
      "source": [
        "class MLP_nested(nn.Module):\n",
        "    features_nested: Sequence[int]\n",
        "    features_output: int\n",
        "\n",
        "    def setup(self):\n",
        "      self.mlp = MLP(self.features_nested)\n",
        "      self.output_layer = nn.Dense(self.features_output)\n",
        "\n",
        "    def __call__(self, x):\n",
        "      return self.output_layer(nn.relu(self.mlp(x)))\n",
        "\n",
        "\n",
        "model = MLP_nested([3,4], 1)\n",
        "print(model)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP_nested(\n",
            "    # attributes\n",
            "    features_nested = [3, 4]\n",
            "    features_output = 1\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        mlp: {\n",
            "            Dense_0: {\n",
            "                kernel: DeviceArray([[-0.63572, 0.33321, 0.62651],\n",
            "                             [-0.17779, 0.22005, 0.74431],\n",
            "                             [-0.97726, -0.47203, 0.43659]], dtype=float32),\n",
            "                bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "            },\n",
            "            Dense_1: {\n",
            "                kernel: DeviceArray([[0.22112, 0.87654, 0.22310, -1.22264],\n",
            "                             [-0.32240, 0.94956, -0.04660, 0.39572],\n",
            "                             [-0.03547, -0.75176, 0.35311, 0.59318]], dtype=float32),\n",
            "                bias: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "            },\n",
            "        },\n",
            "        output_layer: {\n",
            "            kernel: DeviceArray([[0.08588],\n",
            "                         [0.64215],\n",
            "                         [-0.46796],\n",
            "                         [-0.10338]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[[0.00000]\n",
            " [-0.21694]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuL88xCopD3J"
      },
      "source": [
        "We can also use the compact notation. The resulting parameters have slightly different names, and random initial values. (They can be made the same, of course.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeY9Jx9NreXm",
        "outputId": "65559e99-0fce-4df6-9e07-be24302c8c6c"
      },
      "source": [
        "class MLP_nested(nn.Module):\n",
        "    features_nested: Sequence[int]\n",
        "    features_output: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "      mlp = MLP(self.features_nested, name=\"my_nested_MLP\")\n",
        "      dense = nn.Dense(self.features_output)\n",
        "      return dense(nn.relu(mlp(x)))\n",
        "\n",
        "model = MLP_nested([3,4], 1)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FrozenDict({\n",
            "    params: {\n",
            "        my_nested_MLP: {\n",
            "            Dense_0: {\n",
            "                kernel: DeviceArray([[-0.22084, -0.04334, -0.92993],\n",
            "                             [-0.42234, 0.45470, -0.09518],\n",
            "                             [0.86117, 0.10712, 0.50940]], dtype=float32),\n",
            "                bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "            },\n",
            "            Dense_1: {\n",
            "                kernel: DeviceArray([[-0.17214, -0.46445, 0.01060, -0.84916],\n",
            "                             [0.56824, 0.08029, 0.90197, -0.04891],\n",
            "                             [0.65304, 0.74382, 0.71842, 0.96025]], dtype=float32),\n",
            "                bias: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "            },\n",
            "        },\n",
            "        Dense_0: {\n",
            "            kernel: DeviceArray([[0.88803],\n",
            "                         [-0.85732],\n",
            "                         [0.13939],\n",
            "                         [0.10748]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[[0.02943]\n",
            " [0.02495]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf8avaA_nGJ1"
      },
      "source": [
        "# Creating modules with parameters\n",
        "\n",
        "Now we illustrate how to create a module with its own parameters, instead of relying on composing built-in primitives. As an example, we write our own dense layer class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUJ98XpSnS8F",
        "outputId": "0238844e-3954-4591-943c-8072597f61d1"
      },
      "source": [
        "class SimpleDense(nn.Module):\n",
        "  features: int # num output features for this layer\n",
        "  kernel_init: Callable = nn.initializers.lecun_normal()\n",
        "  bias_init: Callable = nn.initializers.zeros\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    features_in = inputs.shape[-1] # infer shape from input\n",
        "    features_out = self.features\n",
        "    kernel = self.param('kernel', self.kernel_init, (features_in, features_out))\n",
        "    bias = self.param('bias', self.bias_init, (features_out,))\n",
        "    outputs = jnp.dot(inputs, kernel) + bias\n",
        "    return outputs\n",
        "\n",
        "\n",
        "model = SimpleDense(features=3)\n",
        "print(model)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleDense(\n",
            "    # attributes\n",
            "    features = 3\n",
            "    kernel_init = init\n",
            "    bias_init = zeros\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        kernel: DeviceArray([[0.32718, 0.05599, 0.17998],\n",
            "                     [-0.12295, 0.70712, 0.28972],\n",
            "                     [0.13731, -0.02853, -0.62830]], dtype=float32),\n",
            "        bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "[[0.30842 -0.91549 -0.74603]\n",
            " [0.36248 0.24616 0.36943]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJpBh933-GTW"
      },
      "source": [
        "# Stochastic layers\n",
        "\n",
        "Some layers may need a source of randomness. If so, we must pass them a PRNG in the `init` and `apply` functions, in addition to the PRNG used for parameter initialization. We illustrate this below using dropout. We construct two versions, one which is stochastic (for training), and one which is deterministic (for evaluation). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMSpLucO-Yfj",
        "outputId": "9726f1f3-ca25-4946-f9da-29692b1b034c"
      },
      "source": [
        "class Block(nn.Module):\n",
        "  features: int\n",
        "  training: bool\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    x = nn.Dense(self.features)(inputs)\n",
        "    x = nn.Dropout(rate=0.5)(x, deterministic=not self.training)\n",
        "    return x\n",
        "\n",
        "N = 1; D = 2;\n",
        "x = random.uniform(key, (N,D))\n",
        "\n",
        "model = Block(features=3, training=True)\n",
        "key = random.PRNGKey(0)\n",
        "variables = model.init({'params': key, 'dropout': key}, x)\n",
        "#variables = model.init(key, x) # cannot share the rng\n",
        "print('variables', variables)\n",
        "\n",
        "# Apply stochastic model\n",
        "for i in range(2):\n",
        "  key, subkey = random.split(key)\n",
        "  y = model.apply(variables, x, rngs={'dropout': subkey})\n",
        "  print(f'train output {i}, ', y)\n",
        "\n",
        "# Now make a deterministic version\n",
        "eval_model = Block(features=3, training=False)\n",
        "key = random.PRNGKey(0)\n",
        "#variables = eval_model.init({'params': key, 'dropout': key}, x)\n",
        "for i in range(2):\n",
        "  key, subkey = random.split(key)\n",
        "  y = eval_model.apply(variables, x, rngs={'dropout': subkey})\n",
        "  print(f'eval output {i}, ', y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "variables FrozenDict({\n",
            "    params: {\n",
            "        Dense_0: {\n",
            "            kernel: DeviceArray([[0.99988, -0.14086, -0.99796],\n",
            "                         [1.46673, 0.59637, 0.38263]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "train output 0,  [[0.00000 1.05814 0.00000]]\n",
            "train output 1,  [[3.12202 1.05814 0.32862]]\n",
            "eval output 0,  [[1.56101 0.52907 0.16431]]\n",
            "eval output 1,  [[1.56101 0.52907 0.16431]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHieB2aAumdg"
      },
      "source": [
        "# Mutable variables\n",
        "\n",
        "In addition to parameters, linen modules can contain other kinds of variables, which may be mutable as we illustrate below.\n",
        "Indeed, parameters are just a special case of variable.\n",
        "In particular, this line\n",
        "```\n",
        "p = self.param('param_name', init_fn, shape, dtype)\n",
        "```\n",
        "is a convenient shorthand for this:\n",
        "```\n",
        "p = self.variable('params', 'param_name', lambda s, d: init_fn(self.make_rng('params'), s, d), shape, dtype).value\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAQxx2Tu8xln"
      },
      "source": [
        "## Example: counter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeGNa8zaut41",
        "outputId": "eb8923e0-ed62-46f9-f11b-80dec053e31a"
      },
      "source": [
        "class Counter(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self):\n",
        "    # variable(collection, name, init_fn, *init_args)\n",
        "    counter1 = self.variable('counter', 'count1', lambda: jnp.zeros((), jnp.int32))\n",
        "    counter2 = self.variable('counter', 'count2', lambda: jnp.zeros((), jnp.int32))\n",
        "    is_initialized = self.has_variable('counter', 'count1')\n",
        "    if is_initialized:\n",
        "      counter1.value += 1\n",
        "      counter2.value += 2\n",
        "    return counter1.value, counter2.value\n",
        "\n",
        "\n",
        "model = Counter()\n",
        "print(model)\n",
        "\n",
        "init_variables = model.init(key) # calls the `call` method\n",
        "print('initialized variables:\\n', init_variables)\n",
        "counter = init_variables['counter']['count1']\n",
        "print('counter 1 value', counter)\n",
        "\n",
        "y, mutated_variables = model.apply(init_variables, mutable=['counter'])\n",
        "print('mutated variables:\\n', mutated_variables)\n",
        "print('output:\\n', y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter()\n",
            "initialized variables:\n",
            " FrozenDict({\n",
            "    counter: {\n",
            "        count1: DeviceArray(1, dtype=int32),\n",
            "        count2: DeviceArray(2, dtype=int32),\n",
            "    },\n",
            "})\n",
            "counter 1 value 1\n",
            "mutated variables:\n",
            " FrozenDict({\n",
            "    counter: {\n",
            "        count1: DeviceArray(2, dtype=int32),\n",
            "        count2: DeviceArray(4, dtype=int32),\n",
            "    },\n",
            "})\n",
            "output:\n",
            " (DeviceArray(2, dtype=int32), DeviceArray(4, dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IaC2RT1v65t"
      },
      "source": [
        "## Combining mutable variables and immutable parameters\n",
        "\n",
        "We can combine mutable variables with immutable parameters.\n",
        "As an example, consider a simplified version of batch normalization, which \n",
        " computes the running mean of its inputs, and adds an optimzable offset (bias) term. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXP19telv_Y_"
      },
      "source": [
        "class BiasAdderWithRunningMean(nn.Module):\n",
        "  decay: float = 0.99\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    is_initialized = self.has_variable('params', 'bias')\n",
        "\n",
        "    # variable(collection, name, init_fn, *init_args)\n",
        "    ra_mean = self.variable('batch_stats', 'mean', lambda s: jnp.zeros(s), x.shape[1:])\n",
        "\n",
        "    dummy_mutable = self.variable('mutables', 'dummy', lambda s: 42, 0)\n",
        "\n",
        "    # param(name, init_fn, *init_args)\n",
        "    bias = self.param('bias', lambda rng, shape: jnp.ones(shape), x.shape[1:]) \n",
        "\n",
        "    if is_initialized:\n",
        "      ra_mean.value = self.decay * ra_mean.value + (1.0 - self.decay) * jnp.mean(x, axis=0, keepdims=True)\n",
        "\n",
        "    return x - ra_mean.value + bias\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_WsMGY8xA_x"
      },
      "source": [
        "\n",
        "The intial variables are:\n",
        "params = (bias=1), batch_stats=(mean=0)\n",
        "\n",
        "If we pass in x=ones(N,D), the  running average becomes\n",
        "$$\n",
        "0.99*0 + (1-0.99)*1 = 0.01\n",
        "$$\n",
        "and the output becomes\n",
        "$$\n",
        "1 - 0.01 + 1 = 1.99\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvXKCE8yxiTu",
        "outputId": "4ddb1117-32a0-481d-d8bb-876010d0e821"
      },
      "source": [
        "key = random.PRNGKey(0)\n",
        "N = 2\n",
        "D = 5\n",
        "x = jnp.ones((N,D))\n",
        "model = BiasAdderWithRunningMean()\n",
        "\n",
        "variables = model.init(key, x)\n",
        "print('initial variables:\\n', variables)\n",
        "nonstats, stats = variables.pop('batch_stats')\n",
        "print('nonstats', nonstats)\n",
        "print('stats', stats)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial variables:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "    },\n",
            "    mutables: {\n",
            "        dummy: 42,\n",
            "    },\n",
            "    params: {\n",
            "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "nonstats FrozenDict({\n",
            "    mutables: {\n",
            "        dummy: 42,\n",
            "    },\n",
            "    params: {\n",
            "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "stats FrozenDict({\n",
            "    mean: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytr2_w9U12PT",
        "outputId": "30555a51-9b09-4ef2-8222-98c9b52e4a47"
      },
      "source": [
        "y, mutables = model.apply(variables, x, mutable=['batch_stats'])\n",
        "print('output', y)\n",
        "print('mutables', mutables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output [[1.99000 1.99000 1.99000 1.99000 1.99000]\n",
            " [1.99000 1.99000 1.99000 1.99000 1.99000]]\n",
            "mutables FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([[0.01000, 0.01000, 0.01000, 0.01000, 0.01000]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1g2GW3f3B-Z"
      },
      "source": [
        "To call the function with the updated batch stats, we have to stitch together the new mutated state with the old state, as shown below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpBb21A72Bdj",
        "outputId": "d5ce7521-90c4-48a0-a180-4f02be5fe5f8"
      },
      "source": [
        "\n",
        "variables = unfreeze(nonstats)\n",
        "print(variables)\n",
        "variables['batch_stats'] = mutables['batch_stats']\n",
        "variables = freeze(variables)\n",
        "print(variables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'mutables': {'dummy': 42}, 'params': {'bias': DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32)}}\n",
            "FrozenDict({\n",
            "    mutables: {\n",
            "        dummy: 42,\n",
            "    },\n",
            "    params: {\n",
            "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
            "    },\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([[0.01000, 0.01000, 0.01000, 0.01000, 0.01000]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa7nH74Y5-Lg"
      },
      "source": [
        "If we pass in x=2*ones(N,D), the running average gets updated to\n",
        "$$\n",
        "0.99 * 0.01 + (1-0.99) * 2.0 = 0.0299\n",
        "$$\n",
        "and the output becomes\n",
        "$$\n",
        "2- 0.0299 + 1 = 2.9701\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2dF2si51QN5",
        "outputId": "6177ee1c-41b7-40e6-d954-d0c1c85b0180"
      },
      "source": [
        "\n",
        "x = 2*jnp.ones((N,D))\n",
        "y, mutables = model.apply(variables, x, mutable=['batch_stats'])\n",
        "print('output', y)\n",
        "print('batch_stats', mutables)\n",
        "\n",
        "assert np.allclose(y, 2.9701)\n",
        "assert np.allclose(mutables['batch_stats']['mean'], 0.0299)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output [[2.97010 2.97010 2.97010 2.97010 2.97010]\n",
            " [2.97010 2.97010 2.97010 2.97010 2.97010]]\n",
            "batch_stats FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([[0.02990, 0.02990, 0.02990, 0.02990, 0.02990]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnBmgGxOoPKU"
      },
      "source": [
        "# Optimization\n",
        "\n",
        "Flax has several built-in (first-order) optimizers, as we illustrate below on a random linear function. (Note that we can also fit a model defined in flax using some other kind of optimizer, such as that provided by the [optax library](https://github.com/deepmind/optax).)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTHgj_pMra3H",
        "outputId": "d142c2bb-c725-47e6-8cba-5b55f9f16b48"
      },
      "source": [
        "D = 5\n",
        "key = jax.random.PRNGKey(0)\n",
        "params = {'w': jax.random.normal(key, (D,))}\n",
        "print(params)\n",
        "\n",
        "x = jax.random.normal(key, (D,))\n",
        "\n",
        "def loss(params):\n",
        "  w = params['w']\n",
        "  return jnp.dot(x, w)\n",
        "\n",
        "loss_grad_fn = jax.value_and_grad(loss)\n",
        "v, g = loss_grad_fn(params)\n",
        "print(v)\n",
        "print(g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)}\n",
            "3.375659\n",
            "{'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KdmBHa8oWFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3695c5f5-339c-4e27-d80e-30d100ddae66"
      },
      "source": [
        "from flax import optim\n",
        "optimizer_def = optim.Momentum(learning_rate=0.1, beta=0.9)\n",
        "print(optimizer_def)\n",
        "\n",
        "optimizer = optimizer_def.create(params) \n",
        "print(optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<flax.optim.momentum.Momentum object at 0x7fbd09abceb8>\n",
            "Optimizer(optimizer_def=<flax.optim.momentum.Momentum object at 0x7fbd09abceb8>, state=OptimizerState(step=DeviceArray(0, dtype=int32), param_states={'w': _MomentumParamState(momentum=DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32))}), target={'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JpgauX_ox_w",
        "outputId": "c649c61c-93ba-41a0-a834-2c254a53a243"
      },
      "source": [
        "for i in range(10):\n",
        "  params = optimizer.target\n",
        "  loss_val, grad = loss_grad_fn(params)\n",
        "  optimizer = optimizer.apply_gradient(grad)\n",
        "  params = optimizer.target\n",
        "  print('step {}, loss {:0.3f}, params {}'.format(i, loss_val, params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, loss -10.593, params {'w': DeviceArray([-0.71837, 4.90788, 1.03673, -4.77677, -0.93493], dtype=float32)}\n",
            "step 1, loss -12.910, params {'w': DeviceArray([-0.85316, 5.82877, 1.23126, -5.67306, -1.11035], dtype=float32)}\n",
            "step 2, loss -15.332, params {'w': DeviceArray([-0.99326, 6.78590, 1.43345, -6.60462, -1.29268], dtype=float32)}\n",
            "step 3, loss -17.849, params {'w': DeviceArray([-1.13813, 7.77566, 1.64252, -7.56794, -1.48122], dtype=float32)}\n",
            "step 4, loss -20.453, params {'w': DeviceArray([-1.28730, 8.79477, 1.85780, -8.55983, -1.67536], dtype=float32)}\n",
            "step 5, loss -23.133, params {'w': DeviceArray([-1.44033, 9.84031, 2.07866, -9.57743, -1.87453], dtype=float32)}\n",
            "step 6, loss -25.884, params {'w': DeviceArray([-1.59685, 10.90963, 2.30454, -10.61818, -2.07823], dtype=float32)}\n",
            "step 7, loss -28.696, params {'w': DeviceArray([-1.75650, 12.00035, 2.53494, -11.67977, -2.28600], dtype=float32)}\n",
            "step 8, loss -31.565, params {'w': DeviceArray([-1.91897, 13.11033, 2.76941, -12.76010, -2.49745], dtype=float32)}\n",
            "step 9, loss -34.485, params {'w': DeviceArray([-2.08397, 14.23764, 3.00754, -13.85730, -2.71220], dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ITTDWT2ECxC"
      },
      "source": [
        "# Worked example: MLP for MNIST \n",
        "\n",
        "We demonstrate how to fit a shallow MLP to MNIST using Flax.\n",
        "We use this function:\n",
        "https://github.com/probml/pyprobml/blob/master/scripts/fit_flax.py\n",
        "To allow us to edit this file locally (in colab), and push commits back to github, we sync this colab with github. (For details see [this colab](https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/intro/colab_intro.ipynb), the cell labeled \"Working with github\".)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vavamofruHS_"
      },
      "source": [
        "## Import code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3KR7bMQWQ2A",
        "outputId": "218e5ea7-d855-4f8a-9c6d-e509a6d6641b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OhoJQUnuE1Q",
        "outputId": "d40b0ab5-8fb3-4286-a925-51e41be70d40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive/ssh/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "id_rsa\tid_rsa.pub  known_hosts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItaIH9dyocZA",
        "outputId": "aebdafd4-9c3c-4bb5-a9a7-f72dbe21f979"
      },
      "source": [
        "!rm -rf git_colab*.*\n",
        "!wget https://raw.githubusercontent.com/probml/pyprobml/master/scripts/git_colab.py   \n",
        "import git_colab as gc"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-19 21:52:51--  https://raw.githubusercontent.com/probml/pyprobml/master/scripts/git_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1243 (1.2K) [text/plain]\n",
            "Saving to: ‘git_colab.py’\n",
            "\n",
            "git_colab.py        100%[===================>]   1.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-01-19 21:52:51 (57.6 MB/s) - ‘git_colab.py’ saved [1243/1243]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUYY3-N4uWYh",
        "outputId": "a9e455f0-0b49-4429-ad1d-689f5a6936cc"
      },
      "source": [
        "\n",
        "!rm -rf pyprobml\n",
        "gc.git_ssh(\"git clone https://github.com/probml/pyprobml.git\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "executing command via ssh: git clone git@github.com:probml/pyprobml.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjUVc9yKvFFP"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OQ7d5hfulh7r",
        "outputId": "744eedb7-72d1-4912-fe55-bd79c3fbd3fe"
      },
      "source": [
        "from google.colab import files\n",
        "files.view('/content/pyprobml/scripts/fit_flax.py')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/pyprobml/scripts/fit_flax.py\")"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKnFd4MFu_jE",
        "outputId": "0d715cf0-8b5c-495d-a1c4-4357d3fe1038"
      },
      "source": [
        "import pyprobml.scripts.fit_flax as ff\n",
        "ff.test()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing fit-flax\n",
            "train step: 0, loss: 1.9384, accuracy: 0.00\n",
            "train step: 1, loss: 1.8272, accuracy: 0.33\n",
            "FrozenDict({\n",
            "    Dense_0: {\n",
            "        bias: DeviceArray([-0.06866, -0.05334, 0.02114, 0.03266, 0.01460, 0.02043,\n",
            "                     0.03476, 0.03221, 0.04559, -0.07938], dtype=float32),\n",
            "        kernel: DeviceArray([[-0.08550, -0.05451, 0.00159, 0.01994, 0.00922, 0.01030,\n",
            "                      0.02837, 0.02299, 0.01819, 0.02941],\n",
            "                     [0.10214, -0.07613, -0.01284, -0.00828, -0.00770, -0.00438,\n",
            "                      -0.02352, -0.00740, -0.03010, 0.06821],\n",
            "                     [0.10793, 0.00674, 0.00768, -0.00738, -0.00527, -0.00135,\n",
            "                      -0.02333, -0.01150, -0.00446, -0.06905],\n",
            "                     [-0.01783, -0.02995, 0.00988, 0.01451, 0.00608, 0.00938,\n",
            "                      0.01329, 0.01404, 0.01951, -0.03890],\n",
            "                     [-0.02009, 0.03532, 0.01935, 0.01093, 0.00620, 0.00832,\n",
            "                      0.01147, 0.00773, 0.03048, -0.10972]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "test passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMjR542vpGAQ"
      },
      "source": [
        "Edit the file, then commit changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJXwfqz0-_XJ",
        "outputId": "9191777d-61c1-432a-c5f2-e4d18b109422"
      },
      "source": [
        "# If made any local changes to fit_flax.py, save them to github\n",
        "%cd /content/pyprobml\n",
        "gc.git_ssh(\"git add scripts; git commit -m 'push from colab'; git push\")\n",
        "%cd /content"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pyprobml\n",
            "executing command: git add scripts; git commit -m 'push from colab'; git push\n",
            "# github.com:22 SSH-2.0-babeld-ccb88c3b\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.114.3' to the list of known hosts.\n",
            "Hi murphyk! You've successfully authenticated, but GitHub does not provide shell access.\n",
            "[master 7002db7] push from colab\n",
            " 3 files changed, 42 insertions(+), 28 deletions(-)\n",
            " create mode 100644 scripts/__pycache__/__init__.cpython-36.pyc\n",
            " create mode 100644 scripts/__pycache__/fit_flax.cpython-36.pyc\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.113.4' to the list of known hosts.\n",
            "Counting objects: 7, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (7/7), 3.68 KiB | 3.68 MiB/s, done.\n",
            "Total 7 (delta 4), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To github.com:probml/pyprobml.git\n",
            "   18f72a1..7002db7  master -> master\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_xSZi3v03pC"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwsTgEeW6e2E",
        "outputId": "d4077305-7ab2-45be-d0cf-a16096560542"
      },
      "source": [
        "\n",
        "#train_data = train_data.map(lambda image: tf.image.resize_image_with_crop_or_pad(image, 224, 224))\n",
        "\n",
        "def process_batch(batch):\n",
        "  images = batch['image']\n",
        "  labels = batch['label']\n",
        "  # flatten single image\n",
        "  shape = images.get_shape().as_list()\n",
        "  D = np.prod(shape)\n",
        "  images = tf.reshape(images, (D,))\n",
        "  #images = tf.squeeze(images, axis=[-1]) # convert to N*D where D=28*28\n",
        "  images = tf.cast(images, dtype=tf.float32)\n",
        "  images = ((images / 255.) - .5) * 2. # rescale to -1..1\n",
        "  return {'X': images, 'y': labels} # convert to standard name\n",
        "\n",
        "def load_mnist(split, batch_size):\n",
        "  dataset, info = tfds.load(\"mnist\", split=split, with_info=True)\n",
        "  dataset = dataset.map(process_batch)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  dataset = dataset.cache().repeat()\n",
        "  if split==\"train\":\n",
        "    dataset = dataset.shuffle(10*batch_size, seed=0)\n",
        "  dataset = tfds.as_numpy(dataset) # bye bye TF land\n",
        "  num_examples = info.splits[split].num_examples\n",
        "  return iter(dataset), num_examples\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "train_iter, num_train = load_mnist(\"train\", batch_size)\n",
        "test_iter, num_test = load_mnist(\"test\", batch_size)\n",
        "\n",
        "num_epochs = 3\n",
        "num_steps = num_train // batch_size \n",
        "print(f'{num_epochs} epochs with batch size {batch_size} will take {num_steps} steps')\n",
        "\n",
        "batch = next(train_iter)\n",
        "print(batch['X'].shape)\n",
        "print(batch['y'].shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 epochs with batch size 100 will take 600 steps\n",
            "(100, 784)\n",
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLiWUSjR05BQ"
      },
      "source": [
        "## Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLwAwqd4Nzvy"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  nhidden: int\n",
        "  nclasses: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    if self.nhidden > 0:\n",
        "      x = nn.Dense(self.nhidden)(x)\n",
        "      x = nn.relu(x)\n",
        "    x = nn.Dense(self.nclasses)(x) # logits\n",
        "    x = nn.log_softmax(x) # log probabilities\n",
        "    return x\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JsVFGfU628j"
      },
      "source": [
        "## Training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "KDAJthPTvxI7",
        "outputId": "df6a3715-4049-4de3-bc20-2d1d18760c90"
      },
      "source": [
        "\n",
        "\n",
        "model = Model(nhidden = 128, nclasses=10) \n",
        "rng = jax.random.PRNGKey(0)\n",
        "num_steps = 200\n",
        "\n",
        "params, history =  ff.fit_model(\n",
        "    model, rng, num_steps, train_iter, test_iter, print_every=20)\n",
        "  \n",
        "display(history)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train step: 0, loss: 2.4430, accuracy: 0.09\n",
            "train step: 20, loss: 1.1147, accuracy: 0.60\n",
            "train step: 40, loss: 0.3219, accuracy: 0.92\n",
            "train step: 60, loss: 0.5857, accuracy: 0.81\n",
            "train step: 80, loss: 0.7218, accuracy: 0.75\n",
            "train step: 100, loss: 0.5993, accuracy: 0.81\n",
            "train step: 120, loss: 0.2716, accuracy: 0.93\n",
            "train step: 140, loss: 0.4771, accuracy: 0.83\n",
            "train step: 160, loss: 0.3512, accuracy: 0.89\n",
            "train step: 180, loss: 0.5115, accuracy: 0.86\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>step</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.442956</td>\n",
              "      <td>0.089999996</td>\n",
              "      <td>2.9638493</td>\n",
              "      <td>0.089999996</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.1147307</td>\n",
              "      <td>0.59999996</td>\n",
              "      <td>1.0728567</td>\n",
              "      <td>0.59999996</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.32193664</td>\n",
              "      <td>0.91999996</td>\n",
              "      <td>0.87930954</td>\n",
              "      <td>0.77</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.58570653</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.5977443</td>\n",
              "      <td>0.78999996</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7217762</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.83044803</td>\n",
              "      <td>0.74</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5992826</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.7542707</td>\n",
              "      <td>0.78</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.2716312</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.63344413</td>\n",
              "      <td>0.87</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.47708598</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.62958264</td>\n",
              "      <td>0.75</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.35116953</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.50654083</td>\n",
              "      <td>0.84</td>\n",
              "      <td>160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.51153046</td>\n",
              "      <td>0.85999995</td>\n",
              "      <td>0.3848496</td>\n",
              "      <td>0.89</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   train_loss train_accuracy   test_loss test_accuracy   step\n",
              "0    2.442956    0.089999996   2.9638493   0.089999996    0.0\n",
              "1   1.1147307     0.59999996   1.0728567    0.59999996   20.0\n",
              "2  0.32193664     0.91999996  0.87930954          0.77   40.0\n",
              "3  0.58570653           0.81   0.5977443    0.78999996   60.0\n",
              "4   0.7217762           0.75  0.83044803          0.74   80.0\n",
              "5   0.5992826           0.81   0.7542707          0.78  100.0\n",
              "6   0.2716312           0.93  0.63344413          0.87  120.0\n",
              "7  0.47708598           0.83  0.62958264          0.75  140.0\n",
              "8  0.35116953           0.89  0.50654083          0.84  160.0\n",
              "9  0.51153046     0.85999995   0.3848496          0.89  180.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "RWv2Sspl8EAN",
        "outputId": "f24c9292-d940-47bd-c353-0460162b1ad4"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(history['step'], history['test_accuracy'], 'o-', label='test accuracy')\n",
        "plt.xlabel('num. minibatches')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWe69Z51Q3Kz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}