{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright and License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2021 Kevin P. Murphy (murphyk@gmail.com) and Mahmoud Soliman (mjs@aucegypt.edu)\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GitHub](https://img.shields.io/github/license/probml/pyprobml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/probml/pyprobml/blob/master/notebooks/figures/chapter7_figures.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (a) Central interval and (b) HPD region for a Beta(3,9) posterior. The CI is (0.06, 0.52) and the HPD is (0.04, 0.48). Adapted from Figure 3.6 of \\citep  Hoff09 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!octave -W https://github.com/probml/pmtk3/blob/master/demos/betaHPD.m >> _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (a) Central interval and (b) HPD region for a hypothetical multimodal posterior. Adapted from Figure 2.2 of \\citep  Gelman04 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!octave -W https://github.com/probml/pmtk3/blob/master/demos/postDensityIntervals.m >> _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Computing the distribution of $z=y^2$, where $p(y)$ is uniform (left). The analytic result is shown in the middle, and the Monte Carlo approximation is shown on the right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/change/_of/_vars/_demo1d.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Kernel density estimate derived from a Monte Carlo approximation to $p(\\mu ,\\sigma ^2| \\mathcal  D  )$ where $ \\mathcal  D  = \\  y_n \\sim \\mathcal  N (\\mu =2,\\sigma =1): n=1:1000 \\ $ and we use a diffuse prior. The red star is the MLE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/gauss2d/_pymc3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Updating a Beta prior with a Bernoulli likelihood with sufficient statistics $N_1=4,N_0=1$. (a) Beta(2,2) prior. (b) Uniform Beta(1,1) prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/beta/_binom/_post/_plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (a) Posterior predictive distributions for 10 future trials after seeing $N_1=4$ heads and $N_0=1$ tails. (b) Plug-in approximation based on the same data. In both cases, we use a uniform prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/beta/_binom/_post/_pred/_plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.8:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  A mixture of two Beta distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!octave -W https://github.com/probml/pmtk3/blob/master/demos/mixBetaDemo.m >> _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.9:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (a) The Dirichlet distribution when $K=3$ defines a distribution over the simplex, which can be represented by the triangular surface. Points on this surface satisfy $0 \\leq \\theta _k \\leq 1$ and $\\DOTSB \\sum@ \\slimits@ _ k=1 ^3 \\theta _k = 1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/dirichlet/_3d/_triangle/_plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/dirichlet/_3d/_spiky/_plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Samples from a 5-dimensional symmetric Dirichlet distribution for different parameter values. (a) $\\oset  \\smallsmile   \\boldsymbol  \\alpha    = (0.1,\\ldots ,0.1)$. This results in very sparse distributions, with many 0s. (b) $\\oset  \\smallsmile   \\boldsymbol  \\alpha    = (1,\\ldots ,1)$. This results in more uniform (and dense) distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/dirichlet/_samples/_plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.11:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Inferring the mean of a univariate Gaussian with known $\\sigma ^2$. (a) Using strong prior, $p(\\mu ) = \\mathcal  N (\\mu |0,1)$. (b) Using weak prior, $p(\\mu ) = \\mathcal  N (\\mu |0,5)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!octave -W https://github.com/probml/pmtk3/blob/master/demos/gaussInferParamsMean1d.m >> _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.12:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Sequential updating of the posterior for $\\sigma ^2$ starting from an uninformative prior. The data was generated from a Gaussian with known mean $\\mu =5$ and unknown variance $\\sigma ^2=10$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/gauss/_seq/_update/_sigma/_1d.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.13:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The $NI\\chi ^2(\\mu ,\\sigma ^2|m,\\kappa ,\\nu ,\\sigma ^2)$ distribution. $m$ is the prior mean and $k$ is how strongly we believe this; $\\sigma ^2$ is the prior variance and $\\nu $ is how strongly we believe this. (a) $m=0,\\kappa =1,\\nu =1,\\sigma ^2=1$. Notice that the contour plot (underneath the surface) is shaped like a ``squashed egg''. (b) We increase the strength of our belief in the mean by setting $\\kappa =5$, so the distribution for $\\mu $ around $m=0$ becomes narrower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/nix/_plots.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.14:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Illustration of Bayesian inference for the mean of a 2d Gaussian. (a) The data is generated from $\\mathbf  y _n \\sim \\mathcal  N (\\boldsymbol  \\mu  ,\\boldsymbol  \\Sigma  )$, where $\\boldsymbol  \\mu  =[0.5, 0.5]^ \\top  $ and $\\boldsymbol  \\Sigma  =0.1 [2, 1; 1, 1])$. (b) The prior is $p(\\boldsymbol  \\mu  ) = \\mathcal  N (\\boldsymbol  \\mu  |\\boldsymbol  0 ,0.1 \\mathbf  I _2)$. (c) We show the posterior after 10 data points have been observed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!octave -W https://github.com/probml/pmtk3/blob/master/demos/gaussInferParamsMean2d.m >> _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.17:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Data and inferences for the hierarchical binomial model fit using HMC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/hbayes/_binom/_rats/_pymc3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.19:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  8-schools dataset. (a) Raw data. Each row plots $y_j \\pm \\sigma _j$. Vertical line is the pooled estimate. (b) Posterior 95\\% credible intervals for $\\theta _j$. Vertical line is posterior mean $\\mathbb  E \\left [ \\mu | \\mathcal  D   \\right ]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/schools8/_pymc3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.20:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Marginal posterior density $p(\\tau | \\mathcal  D  )$ for the 8-schools dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/schools8/_pymc3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.21:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Data and inferences for the hierarchical binomial model fit using empirical Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!octave -W https://github.com/probml/pmtk3/blob/master/demos/ebBinom.m >> _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.22:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Ilustration of Bayesian model selection for polynomial regression. (a-c) We fit polynomials of degrees 1, 2 and 3 fit to $N=5$ data points. The solid green curve is the true function, the dashed red curve is the prediction (dotted blue lines represent $\\pm \\sigma $ around the mean). (d) We plot the posterior over models, $p(m| \\mathcal  D  )$, assuming a uniform prior $p(m) \\propto 1$. Adapted from a figure by Zoubin Ghahramani. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/linreg/_eb/_modelsel/_vs/_n.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.23:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Same as \\cref  fig:linregEbModelSelVsN5  except now $N=30$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/linreg/_eb/_modelsel/_vs/_n.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.25:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (a) Log marginal likelihood vs number of heads for the coin tossing example. (b) BIC approximation. (The vertical scale is arbitrary, since we are holding $N$ fixed.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/coins/_model/_sel/_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.26:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Monte Carlo approximation to $p(\\delta | \\mathcal  D  )$. We use kernel density estimation (\\cref  sec:KDE ) to get a smooth plot. The vertical lines represent a ROPE of $[-0.1, 0.1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!octave -W https://github.com/probml/pmtk3/blob/master/demos/amazonSellerDemo.m >> _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.27:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (a) Histogram of Newcomb's data. (b) Histograms of data sampled from Gaussian model. (c) Histogram of test statistic on data sampled from the model, which represents $p(\\tau (\\cc@accent  \"707E   \\mathcal  D   ^s)| \\mathcal  D  )$, where $\\tau ( \\mathcal  D  )=\\qopname m min \\ y \\in  \\mathcal  D  \\ $. The vertical line is the test statistic on the true data, $\\tau ( \\mathcal  D  )$. (d) Same as (c) except $\\tau ( \\mathcal  D  ) = \\mathbb  V \\  y \\in  \\mathcal  D  \\ $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!octave -W https://github.com/probml/pmtk3/blob/master/demos/newcombPlugin.m >> _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.28:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Approximating the posterior of a beta-Bernoulli model. (a) Grid approximation using 20 grid points. (b) Laplace approximation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/beta/_binom/_approx/_post/_pymc3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.29:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Approximating the posterior of a beta-Bernoulli model using Gaussian approximation to the logits, $q(\\alpha ) = \\mathcal  N (\\mu ,\\sigma )$, where $\\alpha =\\mathrm  logit (\\theta )$. (a) Estimate of variational mean over time. (b) Estimate of variational standard deviation over time. (c) ELBO over time. (d) Kernel density estimate of the original parameter $\\theta \\in [0,1]$ derived from samples from the variational posterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/beta/_binom/_approx/_post/_pymc3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7.30:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Approximating the posterior of a beta-Bernoulli model using MCMC. (a) Kernel density estimate derived from samples from 4 independent chains. (b) Trace plot of the chains as they generate posterior samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run https://github.com/probml/pyprobml/blob/master/scripts/beta/_binom/_approx/_post/_pymc3.py"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
